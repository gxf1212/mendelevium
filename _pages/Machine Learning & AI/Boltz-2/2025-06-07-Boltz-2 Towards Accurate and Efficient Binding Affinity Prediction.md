---
title: "MIT Releases Boltz-2: AI Binding Affinity Prediction Matches FEP Performance with 1000x Speedup"
date: "2025-06-07"
tags: [boltz-2, binding-affinity, ai, drug-discovery, fep, mit, deep-learning, protein-ligand, molecular-dynamics]
---
# 重磅！MIT发布Boltz-2：AI预测结合亲和力首次媲美FEP，千倍加速药物发现

原标题：Boltz-2: Towards Accurate and Efficient Binding Affinity Prediction

链接：http://jeremywohlwend.com/assets/boltz2.pdf

![image-20250606225926808](Boltz-2 Towards Accurate and Efficient Binding Affinity Prediction.assets\image-20250606225926808.png)

生物分子相互作用的精确建模是现代生物学的核心挑战。近年来，以AlphaFold3 和Boltz-1 为代表的AI模型在生物分子复合物的**结构预测**方面取得了革命性突破。然而，**结合亲和力**——这一衡量分子功能和药物疗效的关键性质——的预测仍然是该领域一块难啃的硬骨头。

今天，我们为您深度解读来自MIT CSAIL、Jameel Clinic以及Valence Labs等机构的最新成果——**Boltz-2**。这不仅是一个结构预测模型，更是一个在**结构与亲和力预测**两大战场上均取得卓越表现的全新基础模型。

**Boltz-2的核心突破在于，它是首个在小分子-蛋白质结合亲和力估算方面，性能媲美领域“金标准”——自由能微扰（FEP）方法的AI模型，同时计算效率提升了至少1000倍！**

此外，Boltz-2还引入了多项创新的可控性功能，并与分子生成模型相结合，展示了发现多样化、可合成、高亲和力苗头化合物的有效工作流程。为了推动整个领域的创新，团队已将Boltz-2的模型权重、推理和训练代码在许可协议下完全开源。

下面，让我们一同深入探索Boltz-2的技术细节、惊人性能和深远影响。

------

## 1 | 引言：为何Boltz-2如此重要？

生物体内的复杂生命过程由蛋白质、DNA、RNA和小分子等生物分子间的相互作用所主导。精确阐明这些相互作用是理解生命、对抗疾病的基石。Boltz-2正是在这一背景下诞生的新型基础模型，它继承并发展了AlphaFold3和Boltz-1的衣钵，不仅提升了跨模态的结构预测准确性，还将预测能力从静态复合物扩展到了动态系综，并在物理真实性上设立了新标准。

然而，Boltz-2最与众不同的标志性特征，是其强大的**结合亲和力预测能力**。结合亲和力衡量小分子（药物）与蛋白质靶点结合的紧密程度，它直接关系到药物是否能作用于预期靶点，以及药效是否足够强大以产生治疗效果。尽管其在药物设计中至关重要，但计算机辅助的亲和力预测长期以来都是一个悬而未决的挑战。

此前，该领域的玩家面临着一个两难的**性能/计算时间权衡**：

- **高精度方法**：以**自由能微扰（FEP）**为代表的原子模拟方法最为精确，但其计算成本极高、速度极慢，无法用于大规模筛选。
- **快速方法**：以**分子对接（Docking）**为代表的方法速度快，但其精度不足以提供可靠的信号。

**迄今为止，没有任何一个AI模型能够在结合亲和力预测的准确性上与FEP方法或实验室检测相提并论。**

Boltz-2的出现，正是为了打破这一僵局。它的成功建立在**数据管理**和**表示学习**两大基石之上。通过标准化数百万个生化实验数据，并从这些含噪数据中提取有效信号，Boltz-2解决了训练数据这一核心障碍。同时，其亲和力预测能力根植于驱动共折叠过程的强大潜空间表示，这意味着**结构建模的进步直接推动了亲和力预测的飞跃**。

<img src="Boltz-2 Towards Accurate and Efficient Binding Affinity Prediction.assets\image-20250606225958759.png" alt="image-20250606225958759" style="zoom: 33%;" />

## 2 | 数据：模型的基石

强大的基础模型离不开高质量、大规模的数据聚合与管理。Boltz-2的训练数据主要分为两类：结构数据和结合亲和力数据。

### 2.1 结构数据：从静态到动态，从真实到蒸馏

与Boltz-1相比，Boltz-2在结构数据的多样性和来源上进行了大幅扩展。

- **拥抱动态系综**：Boltz-1主要基于PDB数据库中每个系统的单一静态结构进行训练。而Boltz-2的一大进步是引入了**系综（ensembles）**的概念，即一个分子并非只有一种构象。这些系综数据同时来自：

  - **实验技术**：如核磁共振（NMR）等多构象实验数据。
  - **计算模拟**：如来自MISATO、ATLAS和md-CATH等大型公开项目的分子动力学（MD）模拟轨迹。 这样做目标是让Boltz-2不仅能学习晶体结构所代表的单一平衡点，还能理解分子的局部波动和全局结构变化，从而更好地捕捉**蛋白质动态学**。

  > **进一步解释：MD数据集细节**
  >
  > - **MISATO**：包含在300K温度下进行8纳秒（ns）NVT系综模拟的轨迹。该数据集主要关注蛋白质-配体复合物，并移除了配体漂移过远（>12Å）的轨迹。
  > - **ATLAS**：包含在300K温度下进行100纳秒（ns）NPT系综模拟的轨迹。Boltz-2从中采样最后10纳秒的构象用于训练，以捕捉更接近平衡态的动态行为。
  > - **mdCATH**：包含在320K温度下进行NVT系综模拟的轨迹，模拟时间最长可达500纳秒。Boltz-2使用轨迹的最后10%进行训练。
  >
  > 通过整合这些长时程、大规模的MD数据，Boltz-2得以学习到比静态晶体结构丰富得多的构象信息。

- **引入B-factor监督**：为了进一步增强模型对局部动力学的理解，Boltz-2的Trunk模块末端的单一表示被监督用于预测来自实验和MD轨迹的**B-factor**（温度因子，反映原子位置的不确定性或柔性）。

  > 进一步解释：B-factor监督的作用
  >
  > B-factor是晶体学中用来描述原子柔性的一个参数，值越高代表原子位置越不确定、越灵活。在MD模拟中，可以通过原子的均方根涨落（RMSF）计算得到类似的量。通过让模型直接预测B-factor，其最终作用是强制模型不仅学习原子的平均位置（三维结构），还要学习每个原子的“动态个性”或“活动范围”。这使得模型对蛋白质的柔性区域（如loop区）和刚性区域（如α-螺旋或β-折叠的核心）有更深刻的理解，从而生成更符合真实动态特性的结构。

- **大规模蒸馏数据**：为了增加训练数据的规模和多样性，Boltz-2广泛采用了**蒸馏（distillation）**技术。

  > 通俗解释：什么是蒸馏？
  >
  > 想象一下，我们有一位非常厉害的“老师傅”（一个已经很强大的模型，如AlphaFold2或Boltz-1）。我们让这位“老师傅”对大量它没见过但我们认为有价值的“原材料”（如蛋白质或RNA序列）进行预测，并筛选出那些它非常有信心的“作品”（高置信度的预测结构）。然后，我们把这些高质量的“作品”当作新的、可靠的训练数据，用来教“学徒”（即正在训练的Boltz-2）。通过这种方式，我们可以极大地扩充训练集，让模型见到更多样化的例子，尤其是在实验数据稀疏的领域。

  Boltz-2的蒸馏数据包括：

  - AlphaFold2预测的单链蛋白质结构。
  - Boltz-1预测的多种复合物结构，涵盖**单链RNA、蛋白质-DNA、配体-蛋白质、MHC-多肽**以及**MHC-多肽-TCR**等多种相互作用类型。

### 2.2 结合亲和力数据：在噪声中淘金

尽管PubChem、ChEMBL等公共数据库中存在数以百万计的结合亲和力数据点，但由于实验方案的差异和噪声，将它们整合成一个可用的训练集是出了名的困难。Boltz-2团队为此设计了一套精细的数据管理策略。

> 进一步解释：“在噪声中淘金”的具体策略
>
> “淘金”的过程旨在从海量的、良莠不齐的公开数据中筛选出最可靠、信息量最大的部分。具体策略包括：
>
> 1. **来源筛选**：优先选择如ChEMBL和BindingDB中手动策展、可信度高的数据。对于PubChem中的数据，严格筛选实验类型（如限定为生化或功能性实验）和置信度等级。
> 2. **数据一致性处理**：将所有不同类型的亲和力测量值（如Ki,Kd,IC50等）统一转换为log10尺度，并以μM为标准单位，便于模型学习。
> 3. **噪声实验剔除**：移除那些数据点过少、活性值过于集中（标准差过低，无法提供活性差异信息）或化学多样性过低的实验（例如，只测试了一系列非常相似的化合物），因为这些数据可能无法帮助模型学习普适的规律。
> 4. **标签可靠性增强**：对于来自高通量筛选（HTS）的二元标签（结合/不结合），这是一个噪声重灾区。团队通过交叉验证的方式，要求一个“结合”的标签必须在独立的定量实验中得到确认，从而过滤掉大量假阳性。
> 5. **负样本扩充**：通过“合成诱饵分子”策略，为每个已知的结合物匹配一个结构相似度低但来自相似靶点筛选的“不结合”分子，这极大地丰富了负样本空间，帮助模型更好地区分结合物与非结合物。
>
> 通过这一系列精细的操作，Boltz-2得以在一个相对“干净”且信息丰富的数据集上进行训练，这是其成功的关键前提。

#### 2.2.1 满足不同需求的混合数据集

药物发现的不同阶段对亲和力数据的要求不同：

- **苗头化合物发现（Hit Discovery）**：需要大规模、**二元标签**（结合/不结合）的数据来从大型化合物库中识别出可能的结合物。
- **苗头到先导/先导优化（Hit-to-lead/Lead Optimization）**：需要精确的、**连续值**的亲和力测量数据（如Ki,Kd,IC50）来区分活性上的细微差异，以指导化合物的精修。

为了同时支持这两种场景，Boltz-2构建了一个包含**二元标签和连续值标签的混合数据集**。下表（原Tab. 1）总结了亲和力训练数据集的统计信息：

| **来源 (Source)**    | **类型 (Type)**  | **监督类型 (Supervision)** | **#结合物 (#Binders)** | **#诱饵 (#Decoys)** | **#靶点 (#Targets)** | **#化合物 (# Compounds)** |
| -------------------- | ---------------- | -------------------------- | ---------------------- | ------------------- | -------------------- | ------------------------- |
| ChEMBL and BindingDB | optimization     | values                     | 1.2M (1.45M)           | 0                   | 2k (2.5k)            | 600k (700k)               |
| PubChem small assays | hit-discovery    | both                       | 10k (13k)              | 50k (70k)           | 250 (300)            | 20k (25k)                 |
| PubChem HTS          | hit-discovery    | binary                     | 200k (400k)            | 1.8M (3.5M)         | 300 (500)            | 400k (450k)               |
| CeMM Fragments       | hit-discovery    | binary                     | 25k (45k)              | 115k (200k)         | 1.3k (2.5k)          | 400 (400)                 |
| MIDAS Metabolites    | hit-discovery    | binary                     | 2k (3.5k)              | 20k (35k)           | 60 (100)             | 400 (400)                 |
| ChEMBL and BindingDB | synthetic decoys | binary                     | 0                      | 1.2M (1.45M)        | 2k (2.5k)            | 600k (700k)               |

*表注：括号中的数值表示在应用结构质量过滤器（ipTM < 0.75）之前的统计数据。*



## 3 | 架构：Boltz-2的心脏

Boltz-2的架构如图2所示，由四个主要模块构成：**Trunk（主干）**、**Denoising Module（去噪模块）**、**Confidence Module（置信度模块）和Affinity Module（亲和力模块）**。下面将重点介绍其与Boltz-1相比的主要区别，特别是可控性组件和亲和力模块。

![image-20250606230108751](Boltz-2 Towards Accurate and Efficient Binding Affinity Prediction.assets\image-20250606230108751.png)

### 3.1 Trunk模块：强大的特征提取器

> 通俗解释：Trunk模块是做什么的？
>
> Trunk模块可以看作是Boltz-2的“大脑”和“感官系统”。它负责接收所有输入信息——包括蛋白质和配体的序列、多序列比对（MSA）信息、结构模板等等——然后通过一系列复杂的计算（主要是PairFormer堆栈和三角注意力运算），将这些原始信息加工成一个高度浓缩、信息丰富的内部表示。这个内部表示就像是模型对整个生物分子复合物的“深刻理解”，后续的所有预测（结构、置信度、亲和力）都将基于这个表示来进行。
>
> **进一步解释：PairFormer和三角注意力**
>
> - **PairFormer**：是Transformer架构的一种变体，专门用于处理成对（pairwise）的信息。在Boltz-2中，它处理的是任意两个氨基酸/核苷酸/原子之间的关系信息，比如它们的距离、相对朝向等。
> - **三角注意力 (Triangle Attention)**：这是AlphaFold系列模型中的一个核心创新。传统的注意力机制只考虑A和B之间的关系，而三角注意力则引入了第三方C，形成一个“三角关系”。它会同时更新A-B之间的关系信息，利用A-C和B-C的关系信息。这种机制使得模型能够更好地推断和强制执行三维空间中的几何约束（比如，如果A离C近，B也离C近，那么A和B之间的距离就不可能太远），这对于精确预测3D结构至关重要。
>
> 通过多层PairFormer和三角注意力的堆叠，Trunk模块能够反复推理和精炼分子间的空间和序列关系，最终输出一个极其强大的内部表示。

Boltz-2对Trunk模块进行了显著的性能优化，通过使用**混合精度（bfloat16）**和`trifast`内核进行三角注意力计算，大大提升了训练和推理的速度及内存效率。这使得训练时的裁剪尺寸（crop size）可以扩大到768个tokens，与AlphaFold3保持一致，从而能处理更大的复合物。

### 3.2 Denoising模块与Boltz-steering：从生成到精炼

> 通俗解释：Denoising模块和Boltz-steering如何工作？
>
> Denoising模块是扩散模型的核心“生成器”。它接收来自Trunk模块的内部表示和随机噪声作为输入，然后像一位雕塑家一样，一步步地从随机的“石块”中“雕刻”出分子的三维结构。
>
> 然而，AI“雕塑家”有时会犯一些不符合物理常识的错误，比如让两个原子“撞”在一起（空间位阻冲突）或者化学键不合理。这时就需要**Boltz-steering**出场了。
>
> **Boltz-steering**是一种在**推理阶段**（即生成新结构时）应用的“物理校正”技术。它就像给雕塑家手上加了一个“力反馈”装置，当他要做出一个不合理的雕刻时（如原子碰撞），这个装置就会施加一个反向的“力”，引导他做出更符合物理现实的调整。Boltz-2集成了这种方法（形成Boltz-2x版本），可以在不牺牲准确性的前提下，显著提高生成结构的物理合理性。

### 3.3 可控性：让用户成为“导演”

许多Boltz-1用户希望能更精确地控制模型的预测，以检验科学假设或整合先验知识。为此，Boltz-2引入了三个全新的可控性组件。

1. **方法条件化 (Method conditioning)**

   > **通俗解释**：这允许用户告诉模型：“请你像一位X射线晶体学家那样思考，给我一个类似晶体结构的结果”，或者“请你模拟分子动力学的过程，展示一个动态系综”。模型在训练时学习了不同实验方法（X射线、NMR、MD等）产生的数据的细微差别，因此可以在预测时对齐到指定的方法类型。

2. **模板条件化与引导 (Template conditioning and steering)**

   > **通俗解释**：这允许用户给模型提供一个相关的复合物结构作为“蓝图”或“参考模板”。与之前的方法不同，Boltz-2不仅支持**多聚体模板**（而不仅仅是单链），还允许用户选择：
   >
   > - **软条件化**：让模型“参考”一下模板，但不强制。
   > - **硬引导（Steering）**：通过Boltz-steering势能，强制模型严格遵循模板的结构。
   >
   > 进一步解释：软条件化与硬引导的定量区别
   >
   > 论文本身没有提供一个直接的指标来定量比较这两者的差异，但我们可以从其机制上理解其定量效果：
   >
   > - **软条件化**是通过特征输入将模板信息提供给模型，模型在做决策时会“看到”这些信息。但它**不提供任何保证**。模型完全可以根据其他信息（如MSA）选择性地忽略模板，最终生成的结构与模板的RMSD可能是任何值。
   > - **硬引导**是通过一个**惩罚势能**来实现的。例如，可以定义一个势能函数Etemplate=∑i∈templatemax(RMSD(xi,xiref)−αcutoff,0)。这个函数的意思是，如果预测的模板区域原子坐标xi与参考模板坐标xiref的RMSD超过了一个预设的阈值αcutoff（比如1Å），就会产生一个惩罚项。在生成过程中，模型会努力最小化这个惩罚，从而**保证**最终模板区域的RMSD会严格控制在αcutoff以内。这是一个**确定性的、可量化的约束**。

3. **接触与口袋条件化 (Contact and pocket conditioning)**

   > **通俗解释**：这允许用户直接指定结构上的约束，就像在地图上画线一样。用户可以指定“A残基和B残基必须相互接触”，或者“这个配体必须绑定到这个口袋里”。同样，这些约束也可以通过steering被强制执行。

### 3.4 Affinity模块：亲和力的最终审判

> 通俗解释：Affinity模块是做什么的？
>
> Affinity模块是Boltz-2实现亲和力预测的核心。它接收由Denoising模块生成的、经过物理校正的3D结构以及Trunk模块提供的丰富表示，然后进行最后的“审判”，并输出两个关键结果：
>
> 1. **结合可能性 (Binding Likelihood)**：一个概率值，回答“这个小分子**是否会**与蛋白质结合？”。
> 2. **亲和力值 (Affinity Value)**：一个连续的数值，回答“如果结合，**结合得有多紧密？**”。这个值可以近似理解为一个类似IC50的度量。

该模块的核心是一个**PairFormer模型**，它专门关注**蛋白质-配体界面**以及**配体内部**的相互作用，而忽略了蛋白质内部的相互作用，从而能更高效地聚焦于结合事件本身。这些相互作用信息被聚合起来，最终通过两个独立的预测头输出上述的结合可能性和亲和力值。

------

## 4 | 训练：如何铸就强大的Boltz-2

Boltz-2的训练过程分为三个主要阶段：**结构训练、置信度训练**和**亲和力训练**。

### 4.1 结构和置信度训练

这部分的训练过程大体上遵循Boltz-1，但有几个关键的改进：

- **计算优化**：允许模型使用更大的裁剪尺寸和更多的迭代次数进行训练。
- **系综监督**：对于来自实验或MD的系综数据，通过聚合所有构象的距离图（distogram）来进行监督，以减少方差。
- **B-factor监督**：如前所述，Trunk的最终表示被额外监督用于预测每个token的B-factor。

> 进一步解释：MD数据在训练中的具体作用
>
> MD数据主要通过两种方式在结构训练中发挥作用：
>
> 1. **监督距离图（Distogram Supervision）**：对于一个MD轨迹产生的构象系综（例如100个构象），模型不是预测其中某一个构象的距离图，而是预测这**100个构象距离图的聚合结果**（例如，平均距离图）。损失函数（如交叉熵）会计算模型预测的距离图与这个聚合目标之间的差异。这种方式让模型学习到一个代表系综平均特征的、更鲁棒的距离表示，而不是过拟合到某个瞬时构象。
> 2. **监督坐标去噪（Coordinate Denoising Supervision）**：在每个训练迭代中，会从MD系综中**随机采样一个构象**。这个被采样的构象会被用于标准的扩散模型坐标加噪和去噪的监督过程。这意味着模型在训练时会见到来自MD轨迹的大量不同构象，从而学习到蛋白质的柔性和构象多样性。
>
> 总结来说，MD数据没有引入新的损失项，而是改变了现有损失项（距离图损失和坐标去噪损失）的**监督目标**，让模型从学习单一静态结构转变为学习动态的构象系综。

### 4.2 亲和力训练

亲和力训练在结构和置信度训练之后进行，并且训练时梯度不会反向传播到Trunk模块，以保护其学到的强大结构表示。

> 进一步解释：亲和力训练的输入
>
> 亲和力模块的输入主要来自已经训练好的Trunk模块。具体来说，其输入是：
>
> 1. **Trunk模块的最终成对表示（final pair representation）**：这是Trunk模块经过多层计算后输出的、蕴含丰富结构和序列信息的二维特征图。
> 2. **预测的原子坐标**：由Denoising模块生成的、最可信的3D结构坐标。
>
> 换言之，亲和力模块是在一个高质量的、由模型自身预测的3D结构基础上，利用Trunk模块学到的深层**内部表示（representation）**来进行预测的。它不需要原始的序列或MSA信息，因为这些信息已经被Trunk模块“编码”进了它的输入表示中。

其训练流程包含多个精心设计的组件：

1. **口袋预计算和裁剪**：为了聚焦于最相关的相互作用并提高效率，训练流程首先对结合口袋进行预计算和裁剪。

2. **自定义采样策略**：设计了一种特殊的采样器，它能够**平衡结合物和诱饵分子的比例**，并优先考虑那些**信息量大、反差高**（即活性差异显著）的实验数据，以鼓励模型学习“活性悬崖”（activity cliffs）——即微小结构变化导致巨大活性差异的现象。

3. 鲁棒的损失函数

   ：

   - **二元分类任务**（结合/不结合）：使用**Focal Loss**来解决类别不平衡问题（诱饵分子远多于结合物）。

   - 连续值回归任务

     （亲和力大小）：

     - 使用**Huber Loss**，这是一种对噪声数据更鲁棒的损失函数。
     - 创新性地同时监督**绝对亲和力值**和**同批次内成对的亲和力差异**，并给予后者更高的权重。监督差异值可以有效抵消不同实验条件（如底物浓度）带来的系统性偏差。

### 4.3 与分子生成器结合的训练

Boltz-2不仅能预测，还能**指导**新分子的生成。在评估中，Boltz-2被用作一个**打分函数（或奖励函数）**来训练一个名为**SynFlowNet**的分子生成器。

> 进一步解释：SynFlowNet的具体架构
>
> SynFlowNet是一个基于GFlowNet的、旨在生成可合成分子的模型。其架构和工作流程如下：
>
> - **核心思想**：它将分子生成过程看作一个序列化的决策过程（马尔可夫决策过程，MDP）。每一步，模型都会从一个包含**反应类型**和**化学砌块（building blocks）**的动作空间中选择一个动作，来逐步构建最终的分子。
> - **输入**：模型的输入是当前正在构建的**部分分子**的图表示。
> - **架构**： 
>   - **前向策略网络 (PF)**：这是模型的核心，通常采用**图注意力网络（Graph Transformer）**。它接收部分分子的图表示，输出在当前状态下选择每个可能动作（添加某个砌块或执行某个反应）的概率。
>   - **后向策略网络 (PB)**：用于估计从一个完整分子逆向拆解回起始状态的概率。在SynFlowNet中，为了简化，它被设置为一个均匀分布。
> - **输出**：最终输出的是一个完整的、可以通过预定义反应路径合成的分子。
> - **训练**：它使用一种名为**轨迹平衡损失（Trajectory Balance Loss）**的特殊损失函数进行训练，这个损失函数会利用Boltz-2提供的奖励分数来调整前向策略网络，使其更倾向于生成高奖励（高亲和力）的分子。

------

## 5 | 性能评估：Boltz-2的实力检验

本节将详细介绍Boltz-2在多个维度上的惊人表现，包括结构预测、蛋白质动力学捕捉、结合亲和力预测和虚拟筛选。

### 5.1 结构预测性能：超越前代，缩小差距

- **PDB通用评估集**：在一个包含2024年和2025年发布的、与训练集显著不同的新结构测试集上，Boltz-2的性能与Boltz-1相当或略有提升。尤其是在**RNA链**和**DNA-蛋白质复合物**这些模态上，提升最为显著，这表明大规模蒸馏数据策略对提升模型性能至关重要。与其他模型相比，Boltz-2性能具有竞争力，略优于Chai-1和ProteinX，但稍逊于AlphaFold3。

![image-20250606230304038](Boltz-2 Towards Accurate and Efficient Binding Affinity Prediction.assets\image-20250606230304038.png)

- **抗体基准测试**：在具有挑战性的抗体-抗原结构预测上，Boltz-2相比Boltz-1有中等程度的提升，进一步缩小了开源模型与专有模型（如AlphaFold3）之间的差距。
- **Polaris-ASAP挑战赛**：这是一个针对新冠（SARS-CoV-2）和中东呼吸综合征（MERS-CoV）主蛋白酶配体姿态预测的竞赛。值得注意的是，**Boltz-2无需任何微调或额外的物理弛豫，其开箱即用的性能就与竞赛前5名的顶尖选手相当**，而这些选手大多使用了微调过的Boltz-1或AlphaFold3模型。

![image-20250606230401302](E:\GitHub-repo\mendelevium\_posts\Boltz-2 Towards Accurate and Efficient Binding Affinity Prediction.assets\image-20250606230401302.png)

### 5.2 蛋白质动力学捕捉：更精准的动态视图

通过在分子动力学（MD）数据集（mdCATH和ATLAS）的留出簇上进行评估，结果显示：

1. **MD方法条件化**确实有效，能引导模型生成更多样化的结构，从而更好地捕捉模拟中的构象多样性。
2. 在使用MD条件化时，Boltz-2在多个指标上与专门用于此任务的模型（如BioEmu和AlphaFlow）具有竞争力。
3. 在衡量局部柔性的**RMSF**指标上，Boltz-2生成的MD系综与真实MD轨迹的相关性更强，误差更低，优于Boltz-1、BioEmu和AlphaFlow。

> 进一步解释：除了RMSF还有哪些动力学指标？
>
> 论文中还使用了基于**lDDT（local Distance Difference Test）**的指标来评估动态系综的质量：
>
> - **Precision lDDT**：衡量**预测的每个构象**与**真实MD系综中最接近的构象**之间的相似度。高分表示预测的构象都是合理的。
> - **Recall lDDT**：衡量**真实MD系综中的每个构象**是否都能在**预测的系综中找到一个与之相似的构象**。高分表示模型捕捉到了真实构象的多样性。
> - **Diversity lDDT**：衡量预测系综内部构象之间的平均不相似度（1-lDDT）。高分表示模型生成了多样化的构象，而不是单一的、重复的结构。

![image-20250606230401302 - 副本](E:\GitHub-repo\mendelevium\_posts\Boltz-2 Towards Accurate and Efficient Binding Affinity Prediction.assets\image-20250606230401302 - 副本.png)

### 5.3 关键突破：结合亲和力预测性能媲美FEP

这是Boltz-2最令人瞩目的成就。评估在多个行业公认的、用于“苗头到先导”和“先导优化”的基准数据集上进行。

#### 5.3.1 表现

> **进一步解释：“金标准”FEP及其细节**
>
> - **FEP (Free Energy Perturbation)**：自由能微扰是一种基于统计力学和分子动力学模拟的、计算精确的相对结合自由能（ΔΔG）的方法。它通过在一个“非物理”的路径上，将一个配体A逐渐“突变”成另一个配体B，并计算这个过程中的自由能变化，从而得到两者结合能的差异。因其严格的物理基础，被认为是计算化学领域的“金标准”之一。
> - **FEP+**：在本文中，FEP+特指一个高质量的基准数据集，也代指一种**经过专家手动优化的FEP计算流程**。这种流程中，研究人员会根据具体体系和实验结果，反复调整模拟的参数（如力场、输入结构准备、微扰路径等），以达到与实验结果的最大吻合度。因此，它代表了当前（商业）FEP模拟所能达到的**最高准确性上限**。
> - **OpenFE**：与FEP+相对，OpenFE是一个开源的、采用**自动化、固定流程**的相对FEP方法。它的结果更能代表在没有专家干预的情况下，自动化FEP流程的普遍性能。
> - **力场和模拟细节**：虽然论文没有详述FEP基线的具体参数，但这类计算通常使用标准的生物分子力场（如AMBER, CHARMM, OPLS）和成熟的MD模拟软件包（如AMBER, GROMACS, NAMD）来进行。

- **FEP+基准测试**：
  - **4-靶点子集**：在这个子集上，有多种物理方法的基准可供比较。**Boltz-2取得了0.66的平均皮尔逊相关系数（Pearson R），超越了所有廉价的物理方法（如MM/PBSA）和机器学习基线**。
  - **与FEP的直接对话**：最引人注目的是，**Boltz-2的性能已经接近了领域“金标准”——FEP和ABFE（绝对结合自由能）模拟，而其计算速度快了超过1000倍！**。这在图1的精度-速度Pareto前沿图上得到了清晰的展示。
  - **完整OpenFE子集**：在包含876个复合物的更大规模OpenFE子集上，Boltz-2的性能同样接近了广泛使用的开源相对FEP方法OpenFE。
- **CASP16亲和力挑战赛**：这是一个严格的盲测基准。竞赛参与者有数周时间，并可使用各种定制化的机器学习和物理工具。然而，**Boltz-2在没有任何微调或输入管理的情况下，其性能也明显优于所有排名靠前的参赛者**。

![image-20250606230448781](Boltz-2 Towards Accurate and Efficient Binding Affinity Prediction.assets\image-20250606230448781.png)

#### 5.3.2 模型泛化能力与数据泄漏检验

一个常见的担忧是，AI模型的高性能是否仅仅因为它“记住”了训练集中相似的分子？附录中的**图10**有力地回应了这一质疑。该图分析了FEP+基准测试中，测试化合物与训练集化合物的最大Tanimoto相似度（一种衡量分子结构相似性的指标）和模型预测性能之间的关系。

![image-20250606231227117](Boltz-2 Towards Accurate and Efficient Binding Affinity Prediction.assets\image-20250606231227117.png)

**结论是：模型的预测性能与化合物的相似度之间没有显著的相关性。** 无论测试化合物与训练集中的分子是远亲还是近邻，模型的表现都相对稳定。这强有力地证明了Boltz-2并非简单地“记忆”数据，而是学习到了更普适的、能够泛化到新化学空间的物理和化学规律。

#### 5.3.3 性能的异质性：并非所有靶点都同样出色

附录中的**图12**和**图14**展示了Boltz-2在公共验证集和私有工业界数据集上，针对**每一个具体实验（assay）**的性能散点图。这些图揭示了一个重要且真实的结论：**Boltz-2的性能在不同靶点和实验之间存在显著的异质性。**

![image-20250606231522792](Boltz-2 Towards Accurate and Efficient Binding Affinity Prediction.assets\image-20250606231522792.png)

可以看到，在某些靶点上（如某些激酶），模型的预测值与实验值高度相关（皮尔逊相关系数达0.5+）。然而，在另一些靶点上（如某些GPCR），相关性则要低得多。

这种性能的异质性是符合预期的，也与FEP等物理方法的表现类似。它提醒我们，尽管整体性能强大，但在应用于具体的药物研发项目时，仍需评估模型在特定靶点家族或化学空间中的适用性。这也是未来模型迭代和优化的重要方向。

- **真实的工业界挑战**：团队还在8个来自Recursion的、代表复杂真实世界药物化学项目的**内部盲测数据集**上评估了Boltz-2。结果显示，Boltz-2依然大幅超越其他机器学习基线，并在8个项目中的3个上取得了大于0.55的皮尔逊相关性。但同时，在另外5个项目上性能有限，这也提醒我们，公共基准上的强大性能并不总能直接转化为在所有真实世界复杂问题上的成功，这与FEP方法在某些蛋白类别（如GPCR）上也表现不佳的情况类似。

![image-20250606230533375](Boltz-2 Towards Accurate and Efficient Binding Affinity Prediction.assets\image-20250606230533375.png)

### 5.4 虚拟筛选：大规模、高精度的苗头发现

> 进一步解释：什么是富集因子？
>
> **富集因子（Enrichment Factor, EF）**是评估虚拟筛选性能的一个常用指标。它衡量的是，在筛选出的化合物排名最靠前的某个百分比（例如前1%）中，真实活性化合物的比例相对于在整个数据库中随机抽样的期望比例高了多少倍。例如，如果一个数据库中有1%的活性分子，而你的方法筛选出的排名前1%的分子中有10%是活性分子，那么富集因子EF(1%)就是10%/1% = 10。富集因子越高，说明模型将真实活性分子“富集”到列表顶部的能力越强，这对于实验验证来说至关重要，因为它意味着可以用更少的实验成本找到更多的苗头化合物。

- **回顾性虚拟筛选**：在MF-PCBA数据集（包含多种蛋白家族的高质量生化实验数据）上，Boltz-2展示了强大的苗头化合物发现能力。与之前的机器学习方法、ipTM置信度分数和分子对接相比，**Boltz-2几乎将平均精度（Average Precision）翻了一番，并在0.5%的阈值下实现了18.4的富集因子**。

- **前瞻性虚拟筛选**：为了在更真实的场景中验证Boltz-2，团队进行了一项针对激酶靶点**TYK2**的前瞻性虚拟筛选。

  - **筛选策略**：团队不仅筛选了商业化合物库（Enamine的HLL和Kinase库），还利用了前述的**Boltz-2 + SynFlowNet的生成式筛选流程**，探索了Enamine的760亿规模的REAL Space可合成化合物空间。

  - **验证方法**：由于没有实验数据，团队使用了他们新近开发的高精度绝对FEP流程**Boltz-ABFE**来验证筛选出的化合物的亲和力。

    > 进一步解释：Boltz-ABFE是什么方法？
    >
    > Boltz-ABFE是团队新近开发的一种绝对结合自由能（Absolute Binding Free Energy）计算流程。与计算相对结合能的FEP不同，ABFE旨在直接计算一个配体与受体结合过程的自由能变（ΔG），理论上更具挑战性。Boltz-ABFE的创新之处在于，它将AI与物理模拟相结合：它首先使用Boltz-2来预测蛋白质-配体复合物的3D结构，省去了需要实验晶体结构的昂贵步骤，然后将这个AI预测的结构作为输入，运行后续的绝对自由能物理模拟。这是一个端到端的、无需实验结构的ABFE估算流程。

  - **筛选结果**：

    - Boltz-2成功地从商业库中优先筛选出了高亲和力的配体。
    - **生成式筛选流程表现更佳**：SynFlowNet生成的所有10个最终候选分子都被Boltz-ABFE预测为能够与TYK2结合，且平均亲和力高于固定库筛选出的分子，同时所需的计算预算远低于对整个HLL库的筛选。
    - **新颖性分析**：通过与PDB中已知的TYK2抑制剂进行Tanimoto相似性比较，发现SynFlowNet生成的化合物具有显著的新颖性，与已知结合物的最大骨架相似度仅为0.396。

![image-20250606230627708](Boltz-2 Towards Accurate and Efficient Binding Affinity Prediction.assets\image-20250606230627708.png)

前瞻性筛选的结果令人振奋，尤其是生成式筛选流程。附录中的**图20-23**详细展示了这一流程的成果。

* **更高的亲和力**：SynFlowNet生成的10个最终候选分子，经Boltz-ABFE验证，不仅全部被预测为结合物，而且其**平均结合自由能比从固定商业库（HLL和Kinase库）中筛选出的最佳分子还要好**（见图8）。

* **惊人的新颖性**：这真的是AI的创造力吗？附录**图22**的相似性矩阵和**图23**的分子对比较给出了肯定的答案。

![image-20250606231955941](Boltz-2 Towards Accurate and Efficient Binding Affinity Prediction.assets\image-20250606231955941.png)

分析显示，SynFlowNet生成的化合物与PDB中所有已知的TYK2抑制剂相比，具有**显著的化学新颖性**（最大骨架Tanimoto相似度仅为0.396）。有趣的是，模型自主地“发现”并利用了吡咯并嘧啶（pyrrolopyrimidine）这类经典的激酶铰链区结合基序（hinge-binding motif），但同时将这一基序嫁接到了全新的、多样的化学骨架上。这表明**Boltz-2不仅是在模仿，更是在进行有意义的、基于化学原理的创新组合**。

## 6 | 局限性

尽管Boltz-2取得了巨大成功，但作者也坦诚地指出了模型目前存在的局限性，并计划在未来工作中加以解决：

1. **分子动力学模拟**：尽管比Boltz-1有进步，但在MD相关任务上并未显著超越其他基线模型。这可能与MD数据集在训练后期才被引入以及模型架构未做大改有关。
2. **结构预测挑战**：模型在预测大型复合物的复杂相互作用，以及由结合诱导的大规模构象变化方面仍有不足。
3. **亲和力预测的依赖性**：亲和力模块的准确性高度依赖于上游预测出的3D结构的质量。如果口袋识别错误或界面重构不准，亲和力预测便不可靠。此外，模型目前未明确处理辅因子（如离子、水分子）的作用。
4. **亲和力模块适用范围**：模型在不同实验和靶点上的性能差异很大，需要进一步研究其性能波动的来源，是源于结构预测不准、对某些蛋白家族泛化不足，还是对分布外的化学空间不够鲁棒。



## 7 | 结论

Boltz-2作为一个全新的结构生物学基础模型，在**结构和亲和力预测**两个前沿领域都取得了重大进展。它以更强的物理合理性、更精细的可控性和对局部动力学的更深理解，扩展了其前代产品的共折叠能力。

最关键的是，**Boltz-2是首个在FEP+基准上，结合亲和力预测准确性接近FEP方法的AI模型，同时提供了数量级的计算效率提升**。无论是在回顾性还是前瞻性的评估中，Boltz-2都在药物发现的各个阶段（苗头发现、苗头到先导、先导优化）展现了强大性能。通过与生成模型结合，它更是构建了一个端到端的、经ABFE验证的从头药物设计框架。

**尽管存在一些局限性，但Bol-2的开源发布无疑为整个社区提供了一个极其强大的新基石。** 它不仅有望加速现有药物研发流程，更有可能催生全新的计算驱动的发现范式。未来的研究方向可能包括：整合更精细的物理模型、引入实验反馈的强化学习闭环、增强模型的可解释性以及更好地处理蛋白质的柔性等。

通过在许可协议下开源Boltz-2及其训练流程，该团队希望能为日益壮大的AI与分子科学交叉领域社区提供一个坚实的基础，共同推动药物发现、蛋白质设计和合成生物学的边界，拓展生物分子建模的计算可能性。



## 参考文献 (部分)

- Abramson, J., Adler, J., Dunger, J., et al. (2024). Accurate structure prediction of biomolecular interactions with alphafold 3. *Nature*.
- Wohlwend, J., Corso, G., Passaro, S., et al. (2025). Boltz-1 Democratizing Biomolecular Interaction Modeling.
- Ross, G. A., Lu, C., Scarabelli, G., et al. (2023). The maximal and current accuracy of rigorous protein-ligand binding free energy calculations. *Communications Chemistry*, 6.
- Wu, Z., Koenig, G., Boresch, S., & Cossins, B. (2025). Optimizing absolute binding free energy calculations for production usage. *ChemRxiv preprint*.
- Cretu, M., Harris, C., Igashov, I., et al. (2024). Synflownet: Design of diverse and novel molecules with synthesis constraints. *arXiv preprint*.
- Hahn, D. F., Bayly, C. I., Boby, M. L., et al. (2022). Best practices for constructing, preparing, and evaluating protein-ligand binding affinity benchmarks. *Living journal of computational molecular science*, 4.

更多参考文献请参考原论文

下一期我们将深入一些细节。