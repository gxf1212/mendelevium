---
title: "炼丹师速成指南：深度学习分子属性预测的超参数优化方法学"
date: "2024-11-14"
tags: [hyperparameter-optimization, deep-learning, molecular-property, keras-tuner, hyperband, bayesian-optimization]
description: "系统评估Hyperband、贝叶斯优化等HPO算法在分子属性预测中的效能，Hyperband算法以2-9倍速度优势胜出，推荐使用KerasTuner实现高效并行化超参数调优"
thumbnail: "/assets/img/thumbnail_mine/wh-dpe6lm.jpg"
image: "/assets/img/thumbnail_mine/wh-dpe6lm.jpg"
author: Xufan Gao
lang: zh-CN
---

# 炼丹师速成指南：深度学习分子属性预测的超参数优化方法学


## 本文信息
- **标题**: 用于高效精确分子属性预测的深度神经网络超参数调优方法学
- **作者**: Xuan Dung James Nguyen, Y.A. Liu
- **发表时间**: 2024年11月14日
- **单位**: 弗吉尼亚理工学院暨州立大学, 化学工程系 (美国)
- **引用格式**: Nguyen, X. D. J., & Liu, Y. A. (2025). Methodology for hyperparameter tuning of deep neural networks for efficient and accurate molecular property prediction. *Computers and Chemical Engineering*, *193*, 108928. [https://doi.org/10.1016/j.compchemeng.2024.108928](https://doi.org/10.1016/j.compchemeng.2024.108928)
- O'Malley, T., Bursztein, E., Long, J., Chollet, F. Keras documentation: KerasTuner. https://keras.io/keras_tuner/ (accessed 20 March 2024).

## 摘要

> 本文提出了一套用于分子属性预测 (MPP) 的深度神经网络超参数优化 (HPO) 方法学。以往大多数将深度学习应用于MPP的研究仅对HPO给予了有限的关注，从而导致预测属性的精度未能达到最优。为了提高MPP深度学习模型的效率和准确性，我们必须**尽可能多地优化超参数**，并选择一个能够**支持并行执行HPO的软件平台**。我们在Keras Tuner和Optuna软件包中，比较了**随机搜索、贝叶斯优化、Hyperband算法**以及**贝叶斯-Hyperband组合**在HPO中的表现。我们的结论是，以往MPP研究中未曾使用过的**Hyperband算法，在计算效率上是最高的**；同时，它在预测精度方面能给出**最优或接近最优**的MPP结果。基于我们的案例研究，我们推荐使用Python库 **KerasTuner** 进行HPO。

### 核心结论
- **HPO至关重要**：系统性的超参数优化能够**显著提升**深度学习模型在分子属性预测任务上的准确性，相比默认或手动设置的参数，RMSE可降低数倍。

- **Hyperband算法胜出**：在多种HPO算法（随机搜索、贝叶斯优化、Hyperband、BOHB）的比较中，**Hyperband算法在计算效率上遥遥领先**（快2至9倍），同时其预测精度通常能达到**最优或接近最优**的水平。

- **工具平台推荐**：对于广大化学工程师和科研人员，**KerasTuner** 是一个功能强大、用户友好且易于上手的HPO Python库，它支持并行化，并内置了包括Hyperband在内的多种先进算法。

- **BOHB组合算法的权衡**：尽管理论上更先进的贝叶斯-Hyperband组合算法 (BOHB) 在某些情况下能带来极其微小的精度提升，但其付出的**计算时间成本显著增加**，因此在本文的案例中并不具备性价比优势。

## 背景
近年来，机器学习 (ML)，特别是深度神经网络 (DNN)，在化学、材料和制药领域掀起了一场革命。利用这些强大的数据驱动模型，科学家们能够以前所未有的速度和精度预测分子的各种关键性质，如药物活性、材料的熔融指数、聚合物的玻璃化转变温度等，这一领域被称为分子属性预测 (MPP)。精准的MPP模型不仅能加速新药的发现和新材料的研发进程，还能显著降低实验成本。

然而，构建一个高性能的DNN模型并非易事，它如同一个复杂的“黑箱”，其内部包含了大量需要预先设定的“旋钮”——即**超参数 (Hyperparameters)**。这些参数，如网络的层数、每层的神经元数量、学习率、激活函数的选择等，共同定义了模型的结构和训练方式。它们的组合方式千变万化，不同的组合对模型最终的性能有着天壤之别的影响。手动“炼丹”调参不仅耗时耗力，而且往往带有很大的盲目性，很难找到最优解。

尽管超参数优化 (HPO) 的重要性已在机器学习领域成为共识，但在许多MPP的应用研究中，这一关键步骤却常常被忽视或简化处理。研究者们往往沿用文献中的“经验值”或仅对少数几个参数进行粗略调整。这种做法导致许多已发表的MPP模型的潜力未能被完全发掘，其预测精度远非其能达到的上限。因此，当前领域迫切需要一套**系统、高效且易于实践的HPO方法学**，以指导科研人员如何为他们的MPP任务构建最优的DNN模型。

## 关键科学问题
本文旨在为化学与材料领域的科研人员，特别是那些不具备深厚计算机科学背景的研究者，解决一个核心的实践问题：**如何系统、高效地对用于分子属性预测的深度神经网络进行超参数优化，以在合理的计算时间内获得最高的预测精度？**

为了回答这个宏观问题，作者将其分解为三个具体的、可操作的子问题：

1.  **算法比较**：在现有的主流HPO算法中——**随机搜索、贝叶斯优化和Hyperband**，以及它们的组合——哪一种在MPP任务上能最好地平衡**计算效率（时间成本）**和**预测准确性**？

2.  **平台选择**：市面上有多种支持HPO的软件库，哪一个平台是**免费、用户友好、功能强大且支持并行计算**的，最适合广大科研工作者快速上手？

3.  **方法学构建**：能否提炼出一套**一步一步的、清晰的方法论和实践见解**，让一个初学者也能利用推荐的平台和算法，为自己的MPP问题成功地进行超参数调优？

通过对这些问题的深入探讨，本文的目标是填补从“知道HPO很重要”到“知道如何做好HPO”之间的巨大鸿沟。

## 创新点
- **系统性算法评估**：首次在分子属性预测的背景下，对随机搜索、贝叶斯优化、Hyperband以及BOHB（贝叶斯与Hyperband的组合）等多种主流HPO算法的**计算效率和预测精度**进行了全面的、并排的比较。

- **发现并推荐Hyperband**：研究发现，之前在MPP领域鲜有报道的**Hyperband算法**具有最高的计算效率，同时能达到最优或接近最优的预测精度，并基于此强烈推荐该算法。

- **提供实用工具与流程**：为化学工程师和材料科学家推荐了**KerasTuner**和**Optuna**这两个用户友好的开源Python库，并提供了详细的**分步方法论和Python代码**，极大地降低了实施高级HPO的技术门槛。

- **量化HPO的巨大价值**：通过两个具体的案例研究，明确量化了系统性HPO带来的巨大性能提升。与未经优化的基准模型相比，优化后的模型预测误差（RMSE）**降低了6到8倍**，准确率显著提高，强有力地证明了HPO是构建高性能MPP模型不可或ō缺的一步。

---

## 研究内容
### 方法详述：超参数优化的“武器库”与“靶场”

本文的核心是评估不同的HPO策略。作者首先选择了“武器”（HPO算法和软件平台），然后搭建了“靶场”（两个典型的MPP案例）来进行实证比较。

#### HPO算法与软件平台

**表2：以往MPP研究和本研究中使用的HPO算法与软件平台**

| 文献 | HPO方法 | 软件平台 |
|---|---|---|
| Chen and Tseng (2022) | 贝叶斯优化 | Hyperopt |
| Held et al. (2024) | 随机采样后接TPE算法 | Chemprop |
| **本研究** | 随机搜索，贝叶斯优化，Hyperband，以及BOHB | **KerasTuner**，**Optuna** |

作者选择了两个功能强大且广受欢迎的Python库：
- **KerasTuner**：因其**直观、用户友好且易于编码**而被选为主要平台，特别适合非计算机专业的科研人员。它内置了多种HPO算法，并且**支持并行化**以显著加速调优过程。
- **Optuna**：作为一个补充平台，主要用于实现KerasTuner不支持的**BOHB算法**（贝叶斯优化与Hyperband的组合）。

本文比较了四种核心的HPO算法：
1.  **随机搜索 (Random Search)**：在预定义的超参数空间中随机抽样组合进行测试。
2.  **贝叶斯优化 (Bayesian Optimization)**：一种“智能”搜索方法。它会根据已测试点的表现，建立一个概率代理模型来预测哪些超参数组合**可能**会带来更好的性能，从而更高效地集中探索有希望的区域。
3.  **Hyperband**：一种基于资源分配的快速算法。它采用“逐次减半 (successive halving)”策略：一开始用少量资源（如少量epochs）训练大量超参数组合，然后淘汰掉表现差的一半，再将更多资源分配给表现好的“幸存者”，如此循环，最终找到最优组合。这种“早停”机制避免了在不良超参数上浪费过多计算资源。
4.  **BOHB**：结合了Hyperband和贝叶斯优化的优点。它使用贝叶斯优化来指导选择下一批候选超参数，而不是随机选择，理论上比Hyperband更智能。

**图2：KerasTuner的通用工作流程图**清晰地展示了HPO的迭代过程：选择超参数组合 -> 训练模型 -> 评估模型 -> 重复，直到满足用户设定的条件（如尝试次数），最后用找到的最佳超参数组合构建并评估最终模型。

#### 案例研究（“靶场”）设置

**表3：本文使用的数据集信息**

| | 案例研究1 | 案例研究2 |
|---|---|---|
| 主题 | 预测高密度聚乙烯(HDPE)的**熔融指数 (MI)** | 预测聚合物的**玻璃化转变温度 ($T_g$)** |
| 模型类型 | 全连接深度神经网络 (Dense DNN) | 卷积神经网络 (CNN) |
| 自变量数量 | 9个工艺参数 | (65, 17, 1) 的图像化输入 |
| 样本数量 | 3745 | 352 |
| 输入特征 | 工艺参数（温度、压力等） | 聚合物的SMILES字符串（通过one-hot编码转换为2D矩阵） |

#### 待优化的超参数
作者对两个案例都定义了广泛的超参数搜索空间，涵盖了模型结构和学习算法的方方面面。

**表5：HDPE熔融指数预测的超参数搜索列表与描述（案例1）**

| 超参数名称 | 类型 | 描述 | 搜索空间 |
|---|---|---|---|
| `units_1` | 整数 | 第一个隐藏层的节点数 | 32到512，步长32 |
| `alpha_1` | 浮点数 | 第一个隐藏层Leaky ReLU的斜率 | 0.05到0.5，步长0.05 |
| `dropout_1` | 浮点数 | 第一个dropout层的比率 | 0.05到0.5，步长0.05 |
| `num_layers` | 整数 | 额外的隐藏层数量 | 1到4 |
| `units_hid_i` | 整数 | 额外隐藏层i的节点数 | 32到512，步长32 |
| `alpha_hid_i` | 浮点数 | 额外隐藏层i的Leaky ReLU斜率 | 0.05到0.5，步长0.05 |
| `dropout_hid_i` | 浮点数 | 额外隐藏层i的dropout比率 | 0.05到0.5，步长0.05 |
| `learning_rate` | 选项 | Adam优化器的学习率 | [0.01, 0.001, 0.0001] |

### 结果与分析

#### 案例1：预测HDPE的熔融指数 (MI)

**图1：HDPE熔融指数预测的基础DNN结构。**

- **HPO的巨大威力**：未经优化的基准DNN模型，其预测RMSE高达0.420，R²为0.92012。经过HPO后，最佳模型的**RMSE降低至0.04792**，**R²提升至0.99692**。性能提升了**近8.8倍**，效果惊人。

**表1：有无超参数优化的分子属性预测精度对比**

| 属性预测 | 均方根误差 (RMSE) (无HPO) | 均方根误差 (RMSE) (有HPO) | 决定系数 (R²) (无HPO) | 决定系数 (R²) (有HPO) |
|---|---|---|---|---|
| 1. HDPE熔融指数 | 0.420 | **0.048** | 0.92012 | **0.99692** |
| 2. 聚合物玻璃化转变温度 | 70.60 K | **15.68 K** | - | **0.94829** |

- **算法效率与精度对比**：
    
    **表7：三种HPO算法对HDPE熔融指数预测的总调优时间**
    
    | HPO算法 | 贝叶斯优化 | 随机搜索 | Hyperband |
    |---|---|---|---|
    | 耗时 | 09 h 08 m 51s | 09 h 15 m 12s | **00 h 59 m 55s** |
    
    **表9：新DNN模型在测试集上的性能结果 (HDPE MI预测)**
    
    | 性能指标 | 贝叶斯优化 | **随机搜索** | Hyperband |
    |---|---|---|---|
    | Loss | 0.00463 | **0.00230** | 0.00271 |
    | MAE | 0.04873 | **0.03014** | 0.03561 |
    | RMSE | 0.06803 | **0.04792** | 0.05201 |
    | $R^2$ | 0.99134 | **0.99692** | 0.99669 |

    **结论**：
    1.  **Hyperband效率最高**：调优时间仅为其他两种方法的约1/9。
    2.  **随机搜索意外胜出**：在这个相对简单的DNN模型案例中，随机搜索在测试集和交叉验证上均获得了最佳的预测精度。作者认为，这可能是因为对于简单的DNN，随机搜索已经足够找到一个非常好的解。
    3.  **Hyperband表现稳健**：尽管精度略低于随机搜索，但Hyperband的结果仍然非常出色，远超基准模型，并且考虑其巨大的时间优势，性价比极高。

    **图4-6**分别展示了由贝叶斯优化、随机搜索和Hyperband找到的最佳DNN结构。**图7-12**则展示了对应的损失曲线和预测值-真实值对比图。

#### 案例2：预测聚合物的玻璃化转变温度 ($T_g$)

**图13：聚合物Tg预测的基础CNN结构详情。**

- **HPO再次展现威力**：基准CNN模型的预测准确率约为82%，MAPE (平均绝对百分比误差) 约为6%。经过HPO优化后，最佳模型的**RMSE从70.60 K降至15.68 K**，**MAPE低至3.00%**，R²高达0.95029，性能提升同样非常显著。

- **算法效率与精度对比**：
    
    **表11：新CNN模型在测试集上的性能结果 ($T_g$预测)**
    
    | 性能指标 | 贝叶斯优化 | 随机搜索 | **Hyperband** |
    |---|---|---|---|
    | Loss | 349.021 | 349.432 | **245.903** |
    | MAE | 11.4451 | 11.6328 | **9.1034** |
    | MAPE | 0.03731 | 0.03931 | **0.03002** |
    | RMSE | 18.6821 | 18.6931 | **15.6813** |
    | $R^2$ | 0.92709 | 0.92554 | **0.94829** |

    **结论**：
    1.  **Hyperband全面占优**：对于这个更复杂的CNN模型，**Hyperband在所有性能指标上都显著优于**贝叶斯优化和随机搜索，并且仍然保持着最高的计算效率（比贝叶斯快2.5倍，比随机搜索快3.5倍）。
    2.  **贝叶斯优于随机搜索**：与案例1不同，在此复杂案例中，贝叶斯优化的表现优于随机搜索，更符合理论预期。

    **图14-16**展示了HPO找到的最佳CNN结构。**图17-22**展示了对应的损失曲线和预测-真实值对比。

#### BOHB组合算法的评估

作者进一步使用Optuna库测试了理论上更先进的BOHB算法。

**表13a-d：BOHB与其他算法的性能和时间对比（节选）**

| 案例 | 算法 | 耗时 | RMSE | $R^2$ |
|---|---|---|---|---|
| **HDPE MI** | Hyperband | ~1 h | 0.05201 | 0.99669 |
| | BOHB | ~4 h | 0.05577 | 0.99652 |
| **Polymer $T_g$** | Hyperband | ~6.5 h | 15.6813 | 0.94829 |
| | BOHB | ~11.6 h | **15.5779** | **0.94901** |

**结论**：BOHB算法在简单的DNN案例中表现甚至不如Hyperband。在复杂的CNN案例中，虽然其精度**略微**优于Hyperband，但付出的计算时间成本几乎翻倍。因此，作者认为，**这种微小的精度提升并不足以证明其增加的计算成本是合理的**。

---

## Q&A
- **Q1**: 为什么在进行HPO之前，作者建议先手动确定`batch size`（批处理大小）？
- **A1**: 作者给出了几个非常实际的理由：
    - **1.降低搜索维度**：HPO过程的计算成本随着超参数数量的增加而指数级增长。将`batch size`作为一个超参数会大大增加搜索空间的复杂性，显著延长调优时间。
    - **2.受硬件限制**：`batch size`的大小直接影响内存（特别是GPU显存）的占用。一个过大的`batch size`可能导致内存溢出，使训练崩溃。因此，它通常由硬件条件决定，而不是一个可以自由优化的参数。
    - **3.影响相对较小且有经验法则**：相比于学习率、网络结构等超参数，`batch size`对模型最终性能的直接影响相对较小。通常，适中的值（如32, 64, 128）就能提供稳定的性能。可以依据经验法则和硬件限制先将其固定下来。
    - **4.与学习率的强相关性**：`batch size`和学习率之间存在已知的关系（大batch size通常配合大学习率）。将它们分开处理，先固定`batch size`再精调学习率，可以简化优化问题。

- **Q2**: 在案例1中，理论上更“智能”的贝叶斯优化为什么会输给简单的随机搜索？
- **A2**: 这是一个非常有趣的现象。作者解释说，尽管贝叶斯优化理论上更优，但在某些情况下，尤其是在**有限的尝试次数（本文为500次）**、**简单的模型或非凸的超参数空间**中，它可能表现不佳。贝叶斯优化可能会过早地收敛到某个局部最优区域并反复探索，而简单的随机搜索由于其“盲目性”，反而可能碰巧探索到被贝叶斯优化忽略的、更好的区域。这个结果提醒我们，没有“银弹”，算法的选择有时也依赖于具体问题。

- **Q3**: Hyperband算法的核心优势是什么？为什么它能做到又快又好？
- **A3**: Hyperband的核心优势在于其**高效的资源分配策略**，即“早停”机制。传统方法（如随机搜索）会对每一个超参数组合都进行完整的训练（例如跑满100个epochs），这在坏的组合上浪费了大量时间。而Hyperband则像一个多轮淘汰赛：
    - **第一轮**：快速地用少量资源（如5个epochs）训练大量（如81个）不同的模型。
    - **淘汰**：淘汰掉表现最差的2/3模型。
    - **第二轮**：将更多资源（如15个epochs）分配给幸存的1/3模型（27个）。
    - **循环**：不断重复这个“训练-淘汰-晋级”的过程，直到只剩下一个模型，并对其进行最充分的训练。
    通过这种方式，Hyperband能够迅速剔除没有前途的超参数组合，将宝贵的计算资源集中在少数有潜力的“精英”组合上，从而实现又快又好的效果。

- **Q4**: 这篇论文的方法学对于我自己的研究有什么直接的指导意义？
- **A4**: 指导意义非常直接：
    - **1.必须做HPO**：如果你在使用DNN/CNN做任何预测任务，不要满足于默认参数或文献参数，系统性的HPO能带来巨大的性能提升。
    - **2.首选Hyperband**：在选择HPO算法时，**将Hyperband作为你的首选或基准**。它在速度和性能之间取得了极佳的平衡。
    - **3.使用KerasTuner**：如果你使用TensorFlow/Keras框架，**KerasTuner是一个极好的起点**。它易于使用，功能强大，能让你快速实施Hyperband等算法。
    - **4.并行是关键**：无论使用何种平台，确保利用其**并行计算**功能。在多核CPU或GPU上同时运行多个试验，可以将数天的调优过程缩短到数小时。

---

## 关键结论与批判性总结
### 潜在影响
- ** democratizing HPO**：为化学、材料等领域的非计算机专业研究者提供了一套清晰、实用且高效的深度学习模型优化“标准作业程序 (SOP)”，极大地降低了构建高性能AI模型的门槛。
- **设定新基准**：通过明确展示系统性HPO带来的巨大收益，本研究可能会提升领域内对模型质量的要求，促使未来的MPP研究更加重视并规范化超参数优化这一关键步骤。
- **效率驱动**：强调了Hyperband算法在平衡速度与精度上的巨大优势，为面临计算资源限制的研究者提供了一个极具性价比的选择，有助于加速科研迭代周期。

### 研究局限性
- **模型和任务范围有限**：研究主要集中在两种相对经典的神经网络结构（Dense DNN和CNN）以及两类特定的分子属性预测任务上。其结论是否能直接推广到更前沿、更复杂的模型（如图神经网络GNNs、Transformers）和更多样化的任务（如反应预测、逆向设计）上，仍有待验证。
- **数据集规模**：所用的数据集规模中等（数千和数百个样本）。在更大规模（数十万甚至数百万样本）的数据集上，不同HPO算法的效率和性能排序可能会发生变化。
- **硬件平台单一**：所有测试均在CPU上完成。在现代GPU集群上，不同算法的并行化效率和实际运行时间表现可能会有所不同。

### 未来方向
- **扩展到更复杂的模型**：将本研究的方法学应用到图神经网络（GNNs）和Transformers等更先进的模型架构上，为这些模型的HPO提供指导。
- **更大规模的基准测试**：在更大、更多样化的公开数据集上（如QM9、ZINC、MoleculeNet）重复本研究的比较，以获得更具普适性的结论。
- **自动化流程开发**：开发一个集成了数据预处理、模型构建、HPO（以Hyperband为核心）和模型评估的全自动化工作流，实现分子属性预测的“一键式”优化建模。

> 小编锐评：其实就是速度比贝叶斯快，再调研下再说吧