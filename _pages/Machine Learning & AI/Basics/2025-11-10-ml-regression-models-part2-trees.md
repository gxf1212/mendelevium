---
title: "åˆ†å­æ€§è´¨é¢„æµ‹ï¼šæœºå™¨å­¦ä¹ å›å½’ç®—æ³•è¯¦è§£ï¼ˆäºŒï¼‰æ ‘æ¨¡å‹ä¸æ¢¯åº¦æå‡"
date: "2025-11-10"
tags: [machine-learning, regression, decision-tree, random-forest, xgboost, lightgbm, gradient-boosting]
description: "ç³»åˆ—ç¬¬äºŒç¯‡ï¼šè¯¦è§£å†³ç­–æ ‘ã€éšæœºæ£®æ—ã€æ¢¯åº¦æå‡å®¶æ—ï¼ˆXGBoost/LightGBM/CatBoostç­‰ï¼‰ï¼Œå®æˆ˜ä¸­æœ€å¸¸ç”¨çš„ç«èµ›çº§å›å½’æ¨¡å‹"
thumbnail: "/assets/img/thumbnail/empty.jpg"
image: "/assets/img/thumbnail/empty.jpg"
author: Xufan Gao
lang: zh-CN
---

# åˆ†å­æ€§è´¨é¢„æµ‹ï¼šæœºå™¨å­¦ä¹ å›å½’ç®—æ³•è¯¦è§£ï¼ˆäºŒï¼‰æ ‘æ¨¡å‹ä¸æ¢¯åº¦æå‡

> **ç³»åˆ—å¯¼èˆª**ï¼š
> - [ç¬¬ä¸€ç¯‡ï¼šåŸºç¡€å›å½’æ¨¡å‹](2025-11-10-ml-regression-models-part1-basics.md) - çº¿æ€§æ¨¡å‹ã€æ”¯æŒå‘é‡æœºã€è¿‘é‚»æ–¹æ³•
> - **ç¬¬äºŒç¯‡ï¼šæ ‘æ¨¡å‹ä¸æ¢¯åº¦æå‡**ï¼ˆæœ¬æ–‡ï¼‰- å†³ç­–æ ‘ã€éšæœºæ£®æ—ã€XGBoost/LightGBMç­‰
> - [ç¬¬ä¸‰ç¯‡ï¼šé«˜çº§æ¨¡å‹ä¸åº”ç”¨æŒ‡å—](2025-11-10-ml-regression-models-part3-advanced.md) - ç¥ç»ç½‘ç»œã€æ¦‚ç‡æ¨¡å‹ã€VAEã€æ¨¡å‹é€‰æ‹©æŒ‡å—

## å¯¼è¯»

**æ ‘æ¨¡å‹å’Œæ¢¯åº¦æå‡æ˜¯å®æˆ˜ä¸­æœ€å¸¸ç”¨çš„å›å½’æ–¹æ³•**ï¼Œåœ¨Kaggleç«èµ›å’Œå·¥ä¸šç•Œéƒ½æœ‰ç€å¹¿æ³›åº”ç”¨ã€‚æœ¬ç¯‡å°†è¯¦ç»†ä»‹ç»ï¼š

- **å†³ç­–æ ‘ä¸éšæœºæ£®æ—**ï¼šä»å•æ£µæ ‘åˆ°é›†æˆå­¦ä¹ 
- **æ¢¯åº¦æå‡å®¶æ—**ï¼šGradientBoostingã€XGBoostã€LightGBMã€CatBoostç­‰
- **æ¨¡å‹å¯¹æ¯”**ï¼šå¸®åŠ©ä½ é€‰æ‹©æœ€åˆé€‚çš„æ ‘æ¨¡å‹

è¿™äº›æ¨¡å‹åœ¨åˆ†å­æ€§è´¨é¢„æµ‹ã€è¯ç‰©ç­›é€‰ç­‰ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œé€šå¸¸èƒ½è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚

---

## 1. å†³ç­–æ ‘ä¸éšæœºæ£®æ—

### 1.1 DecisionTreeRegressorï¼ˆå†³ç­–æ ‘å›å½’å™¨ï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šé€šè¿‡ä¸€ç³»åˆ—if-elseè§„åˆ™é€’å½’åˆ’åˆ†ç‰¹å¾ç©ºé—´ã€‚

**sklearnå®ç°**ï¼š`from sklearn.tree import DecisionTreeRegressor`

**åˆ†è£‚å‡†åˆ™**ï¼ˆå›å½’ï¼‰ï¼š
$$
\text{MSE} = \frac{1}{N}\sum_{i=1}^{N}(y_i - \bar{y})^2
$$

æ¯æ¬¡é€‰æ‹©ä½¿å¾—å­èŠ‚ç‚¹MSEä¹‹å’Œæœ€å°çš„ç‰¹å¾å’Œé˜ˆå€¼è¿›è¡Œåˆ†è£‚ã€‚

**ç‰¹ç‚¹**ï¼š
- âœ… **æé«˜å¯è§£é‡Šæ€§**ï¼šå†³ç­–è·¯å¾„æ¸…æ™°å¯è§†åŒ–
- âœ… **è‡ªåŠ¨ç‰¹å¾äº¤äº’**ï¼šæ— éœ€æ‰‹åŠ¨æ„é€ äº¤å‰é¡¹
- âœ… **å¤„ç†ç¼ºå¤±å€¼**ï¼šéƒ¨åˆ†å®ç°æ”¯æŒ
- âŒ **å®¹æ˜“è¿‡æ‹Ÿåˆ**ï¼šéœ€è¦å‰ªææˆ–é™åˆ¶æ·±åº¦
- âš™ï¸ **å…³é”®å‚æ•°**ï¼š
  - `max_depth`ï¼šæ ‘çš„æœ€å¤§æ·±åº¦ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
  - `min_samples_split`ï¼šåˆ†è£‚èŠ‚ç‚¹æ‰€éœ€æœ€å°æ ·æœ¬æ•°
  - `min_samples_leaf`ï¼šå¶å­èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°
- ğŸ“Š **æ¨èåœºæ™¯**ï¼šéœ€è¦è§£é‡Šæ€§çš„åˆ†å­æ€§è´¨é¢„æµ‹

---

### 1.2 RandomForestRegressorï¼ˆéšæœºæ£®æ—å›å½’å™¨ï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šè®­ç»ƒå¤šæ£µå†³ç­–æ ‘ï¼Œé€šè¿‡**Bagging + ç‰¹å¾éšæœºé‡‡æ ·**é™ä½æ–¹å·®ã€‚

**sklearnå®ç°**ï¼š`from sklearn.ensemble import RandomForestRegressor`

**ç®—æ³•æµç¨‹**ï¼š
1. Bootstrapé‡‡æ ·ï¼šä»è®­ç»ƒé›†ä¸­æœ‰æ”¾å›æŠ½å– $N$ ä¸ªæ ·æœ¬
2. ç‰¹å¾éšæœºï¼šæ¯æ¬¡åˆ†è£‚åªè€ƒè™‘éšæœºé€‰æ‹©çš„ $\sqrt{p}$ ä¸ªç‰¹å¾
3. ç‹¬ç«‹è®­ç»ƒæ¯æ£µæ ‘
4. é¢„æµ‹æ—¶å–æ‰€æœ‰æ ‘çš„å¹³å‡å€¼

**ç‰¹ç‚¹**ï¼š
- âœ… **å¼ºå¤§æ³›åŒ–èƒ½åŠ›**ï¼šé›†æˆå­¦ä¹ å‡å°‘è¿‡æ‹Ÿåˆ
- âœ… **ç‰¹å¾é‡è¦æ€§**ï¼šå¯è‡ªåŠ¨è¯„ä¼°ç‰¹å¾è´¡çŒ®åº¦
- âœ… **é²æ£’æ€§å¼º**ï¼šå¯¹å™ªå£°å’Œå¼‚å¸¸å€¼ä¸æ•æ„Ÿ
- âœ… **å¹¶è¡Œè®­ç»ƒ**ï¼šå„æ£µæ ‘ç‹¬ç«‹ï¼ŒGPUåŠ é€Ÿå‹å¥½
- âš™ï¸ **å…³é”®å‚æ•°**ï¼š
  - `n_estimators`ï¼šæ ‘çš„æ•°é‡ï¼ˆé€šå¸¸100-500ï¼‰
  - `max_features`ï¼šåˆ†è£‚æ—¶è€ƒè™‘çš„ç‰¹å¾æ•°ï¼ˆé»˜è®¤ $\sqrt{p}$ï¼‰
  - `max_depth`ï¼šæ ‘çš„æœ€å¤§æ·±åº¦

ğŸ“Š **æ¨èåœºæ™¯**ï¼šé€šç”¨é¦–é€‰ï¼Œå¹³è¡¡æ€§èƒ½ä¸é€Ÿåº¦çš„åˆ†å­æ€§è´¨é¢„æµ‹

---

### 1.3 ExtraTreesRegressorï¼ˆæç«¯éšæœºæ ‘å›å½’å™¨ï¼‰

**ä¸éšæœºæ£®æ—çš„åŒºåˆ«**ï¼š
- ä¸ä½¿ç”¨Bootstrapé‡‡æ ·ï¼Œä½¿ç”¨å…¨éƒ¨è®­ç»ƒæ•°æ®
- åˆ†è£‚é˜ˆå€¼å®Œå…¨éšæœºé€‰æ‹©ï¼ˆè€Œéæœ€ä¼˜é˜ˆå€¼ï¼‰

**sklearnå®ç°**ï¼š`from sklearn.ensemble import ExtraTreesRegressor`

**ç‰¹ç‚¹**ï¼š
- âœ… **è®­ç»ƒæ›´å¿«**ï¼šçœå»é˜ˆå€¼æœç´¢æ­¥éª¤
- âœ… **æ›´ä½æ–¹å·®**ï¼šæ›´å¼ºçš„éšæœºæ€§
- ğŸ“Š **æ¨èåœºæ™¯**ï¼šå¤§è§„æ¨¡åˆ†å­æ•°æ®é›†ï¼Œè¿½æ±‚è®­ç»ƒé€Ÿåº¦

---

### 1.4 å†³ç­–æ ‘ä¸éšæœºæ£®æ—å®¶æ—ç»¼åˆå¯¹æ¯”

| æ¨¡å‹ | sklearnå®ç° | æ ¸å¿ƒä¼˜åŠ¿ | å±€é™æ€§ | è®¡ç®—å¤æ‚åº¦ | è®­ç»ƒé€Ÿåº¦ | æ¨èåœºæ™¯ |
|------|-------------|---------|-------|-----------|---------|---------|
| **DecisionTreeRegressor** | `DecisionTreeRegressor` | æé«˜å¯è§£é‡Šæ€§ï¼Œè‡ªåŠ¨ç‰¹å¾äº¤äº’ | å®¹æ˜“è¿‡æ‹Ÿåˆ | $O(n \log n)$ | å¿« | éœ€è¦è§£é‡Šæ€§çš„å›å½’ä»»åŠ¡ |
| **RandomForestRegressor** | `RandomForestRegressor` | å¼ºå¤§æ³›åŒ–ï¼Œç‰¹å¾é‡è¦æ€§ï¼Œé²æ£’ | å†…å­˜å ç”¨å¤§ | $O(M \cdot n \log n)$ | ä¸­ | é€šç”¨é¦–é€‰å›å½’æ¨¡å‹ |
| **ExtraTreesRegressor** | `ExtraTreesRegressor` | è®­ç»ƒå¿«ï¼Œæ–¹å·®ä½ | éšæœºæ€§å¤§ | $O(M \cdot n \log n)$ | å¿« | å¤§è§„æ¨¡æ•°æ®ï¼Œè¿½æ±‚è®­ç»ƒé€Ÿåº¦ |

**å¯¹æ¯”è¦ç‚¹**ï¼š
- **è®­ç»ƒé€Ÿåº¦**ï¼šExtraTrees > RandomForest > DecisionTree
- **é¢„æµ‹é€Ÿåº¦**ï¼šDecisionTree > RandomForest â‰ˆ ExtraTrees
- **å†…å­˜å ç”¨**ï¼šDecisionTree < ExtraTrees < RandomForest
- **è¿‡æ‹Ÿåˆé£é™©**ï¼šDecisionTree > RandomForest â‰ˆ ExtraTrees

---

## 2. æ¢¯åº¦æå‡å®¶æ—

### 2.1 æ ¸å¿ƒæ€æƒ³

æ¢¯åº¦æå‡ï¼ˆGradient Boostingï¼‰é€šè¿‡**ä¸²è¡Œ**è®­ç»ƒå¤šä¸ªå¼±å­¦ä¹ å™¨ï¼Œæ¯ä¸ªæ–°æ¨¡å‹ä¸“æ³¨äºæ‹Ÿåˆå‰ä¸€ä¸ªæ¨¡å‹çš„æ®‹å·®ï¼ˆæˆ–æ¢¯åº¦ï¼‰ã€‚

---

### 2.2 GradientBoostingRegressorï¼ˆæ ‡å‡†æ¢¯åº¦æå‡å›å½’å™¨ï¼‰

**sklearnå®ç°**ï¼š`from sklearn.ensemble import GradientBoostingRegressor`

**ç®—æ³•æµç¨‹**ï¼š
1. åˆå§‹åŒ– $F_0(\mathbf{x}) = \bar{y}$
2. å¯¹ $m = 1, 2, \ldots, M$ï¼š
   - è®¡ç®—è´Ÿæ¢¯åº¦ï¼ˆä¼ªæ®‹å·®ï¼‰ï¼š$r_{im} = -\frac{\partial L(y_i, F(\mathbf{x}_i))}{\partial F(\mathbf{x}_i)}$
   - è®­ç»ƒå†³ç­–æ ‘ $h_m$ æ‹Ÿåˆ $r_{im}$
   - æ›´æ–°æ¨¡å‹ï¼š$F_m(\mathbf{x}) = F_{m-1}(\mathbf{x}) + \nu \cdot h_m(\mathbf{x})$

å…¶ä¸­ $\nu$ æ˜¯å­¦ä¹ ç‡ã€‚

**ç‰¹ç‚¹**ï¼š
- âœ… **é«˜å‡†ç¡®æ€§**ï¼šé€šå¸¸ä¼˜äºéšæœºæ£®æ—
- âœ… **çµæ´»æŸå¤±å‡½æ•°**ï¼šæ”¯æŒå¤šç§å›å½’ä»»åŠ¡
- âŒ **è®­ç»ƒç¼“æ…¢**ï¼šä¸²è¡Œè®­ç»ƒæ— æ³•å¹¶è¡Œ
- âŒ **æ˜“è¿‡æ‹Ÿåˆ**ï¼šéœ€è¦ç²¾ç»†è°ƒå‚
- âš™ï¸ **å…³é”®å‚æ•°**ï¼š
  - `learning_rate`ï¼šå­¦ä¹ ç‡ï¼ˆ0.01-0.3ï¼‰
  - `n_estimators`ï¼šè¿­ä»£æ¬¡æ•°
  - `max_depth`ï¼šæ ‘æ·±åº¦ï¼ˆé€šå¸¸3-8ï¼‰

---

### 2.3 XGBoostRegressorï¼ˆæç«¯æ¢¯åº¦æå‡å›å½’å™¨ï¼‰

**åˆ›æ–°ç‚¹**ï¼š
- **äºŒé˜¶æ³°å‹’å±•å¼€**ï¼šä½¿ç”¨ä¸€é˜¶å’ŒäºŒé˜¶æ¢¯åº¦ä¿¡æ¯
- **æ­£åˆ™åŒ–**ï¼šåœ¨ç›®æ ‡å‡½æ•°ä¸­åŠ å…¥æ ‘å¤æ‚åº¦æƒ©ç½š
- **åˆ—é‡‡æ ·**ï¼šå€Ÿé‰´éšæœºæ£®æ—çš„ç‰¹å¾é‡‡æ ·
- **å·¥ç¨‹ä¼˜åŒ–**ï¼šå¹¶è¡ŒåŒ–ã€ç¼“å­˜ä¼˜åŒ–ã€GPUåŠ é€Ÿ

**sklearnå®ç°**ï¼š`from xgboost import XGBRegressor`

**ç›®æ ‡å‡½æ•°**ï¼š
$$
\mathcal{L} = \sum_{i=1}^{n}l(y_i, \hat{y}_i) + \sum_{k=1}^{K}\Omega(f_k)
$$

å…¶ä¸­ $\Omega(f_k) = \gamma T + \frac{1}{2}\lambda\|\mathbf{w}\|^2$ï¼ˆ$T$ ä¸ºå¶å­èŠ‚ç‚¹æ•°ï¼Œ$\mathbf{w}$ ä¸ºå¶å­æƒé‡ï¼‰ã€‚

**ç‰¹ç‚¹**ï¼š
- âœ… **Kaggleç¥å™¨**ï¼šç«èµ›ä¸­æœ€å¸¸ç”¨æ¨¡å‹ä¹‹ä¸€
- âœ… **å¤„ç†ç¼ºå¤±å€¼**ï¼šè‡ªåŠ¨å­¦ä¹ ç¼ºå¤±å€¼çš„æœ€ä¼˜æ–¹å‘
- âœ… **é€Ÿåº¦å¿«**ï¼šé«˜æ•ˆå·¥ç¨‹å®ç°
- âš™ï¸ **ç‹¬ç‰¹å‚æ•°**ï¼š
  - `subsample`ï¼šè¡Œé‡‡æ ·æ¯”ä¾‹
  - `colsample_bytree`ï¼šåˆ—é‡‡æ ·æ¯”ä¾‹
  - `reg_alpha`, `reg_lambda`ï¼šL1/L2æ­£åˆ™åŒ–

ğŸ“Š **æ¨èåœºæ™¯**ï¼šè¿½æ±‚æè‡´æ€§èƒ½çš„åˆ†å­æ€§è´¨é¢„æµ‹

---

### 2.4 LGBMRegressorï¼ˆè½»é‡çº§æ¢¯åº¦æå‡å›å½’å™¨ï¼‰

**åˆ›æ–°ç‚¹**ï¼š
- **GOSSï¼ˆGradient-based One-Side Samplingï¼‰**ï¼šä¿ç•™å¤§æ¢¯åº¦æ ·æœ¬ï¼Œéšæœºé‡‡æ ·å°æ¢¯åº¦æ ·æœ¬
- **EFBï¼ˆExclusive Feature Bundlingï¼‰**ï¼šäº’æ–¥ç‰¹å¾æ‰“åŒ…ï¼Œå‡å°‘ç‰¹å¾ç»´åº¦
- **Leaf-wiseç”Ÿé•¿**ï¼šæŒ‰å¶å­èŠ‚ç‚¹æœ€å¤§å¢ç›Šç”Ÿé•¿ï¼ˆè€Œélevel-wiseï¼‰

**sklearnå®ç°**ï¼š`from lightgbm import LGBMRegressor`

**ç‰¹ç‚¹**ï¼š
- âœ… **è®­ç»ƒæå¿«**ï¼šå¤§æ•°æ®é›†ä¸Šæ¯”XGBoostå¿«5-10å€
- âœ… **å†…å­˜å ç”¨ä½**ï¼šç‰¹å¾æ‰“åŒ…æŠ€æœ¯
- âœ… **é«˜å‡†ç¡®æ€§**ï¼šä¸XGBoostç›¸å½“æˆ–æ›´å¥½
- âš ï¸ **æ˜“è¿‡æ‹Ÿåˆ**ï¼šLeaf-wiseç­–ç•¥åœ¨å°æ•°æ®é›†ä¸Šéœ€è¦è°¨æ…
- âš™ï¸ **ç‹¬ç‰¹å‚æ•°**ï¼š
  - `num_leaves`ï¼šæœ€å¤§å¶å­èŠ‚ç‚¹æ•°ï¼ˆæ ¸å¿ƒå‚æ•°ï¼‰
  - `min_data_in_leaf`ï¼šå¶å­æœ€å°æ ·æœ¬æ•°

ğŸ“Š **æ¨èåœºæ™¯**ï¼šå¤§è§„æ¨¡åˆ†å­æ•°æ®åº“ï¼ˆ>10ä¸‡æ ·æœ¬ï¼‰

---

### 2.5 CatBoostRegressorï¼ˆç±»åˆ«æå‡å›å½’å™¨ï¼‰

**åˆ›æ–°ç‚¹**ï¼š
- **Ordered Boosting**ï¼šè§£å†³æ¢¯åº¦ä¼°è®¡åå·®é—®é¢˜
- **åŸç”Ÿæ”¯æŒç±»åˆ«ç‰¹å¾**ï¼šè‡ªåŠ¨å¤„ç†ç±»åˆ«ç¼–ç 
- **å¯¹ç§°æ ‘**ï¼šå‡å°‘é¢„æµ‹æ—¶é—´

**sklearnå®ç°**ï¼š`from catboost import CatBoostRegressor`

**ç‰¹ç‚¹**ï¼š
- âœ… **å¼€ç®±å³ç”¨**ï¼šé»˜è®¤å‚æ•°è¡¨ç°ä¼˜å¼‚
- âœ… **é²æ£’æ€§å¼º**ï¼šå¯¹å‚æ•°ä¸æ•æ„Ÿ
- âœ… **å¤„ç†ç±»åˆ«ç‰¹å¾**ï¼šSMILESå­ç»“æ„ç­‰ç±»åˆ«ä¿¡æ¯
- âŒ **è®­ç»ƒç¨æ…¢**ï¼šç›¸æ¯”LightGBM

ğŸ“Š **æ¨èåœºæ™¯**ï¼šæ··åˆç‰¹å¾ï¼ˆè¿ç»­+ç±»åˆ«ï¼‰çš„åˆ†å­æ•°æ®

---

### 2.6 HistGradientBoostingRegressorï¼ˆç›´æ–¹å›¾æ¢¯åº¦æå‡å›å½’å™¨ï¼‰

**sklearnå®ç°**ï¼š`from sklearn.ensemble import HistGradientBoostingRegressor`

**ç‰¹ç‚¹**ï¼š
- âœ… **åŸç”Ÿæ”¯æŒç¼ºå¤±å€¼**ï¼šæ— éœ€é¢„å¤„ç†
- âœ… **é€Ÿåº¦å¿«**ï¼šåŸºäºç›´æ–¹å›¾çš„åˆ†è£‚
- âœ… **æ— éœ€å®‰è£…é¢å¤–åº“**ï¼šscikit-learnè‡ªå¸¦
- ğŸ“Š **æ¨èåœºæ™¯**ï¼šå¿«é€ŸåŸå‹å¼€å‘ï¼Œä¸éœ€è¦é¢å¤–ä¾èµ–çš„å›å½’ä»»åŠ¡

---

### 2.7 AdaBoostRegressorï¼ˆè‡ªé€‚åº”æå‡å›å½’å™¨ï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šæ¯è½®å¢åŠ é”™è¯¯æ ·æœ¬çš„æƒé‡ï¼Œå¼ºè¿«åç»­æ¨¡å‹å…³æ³¨éš¾åˆ†æ ·æœ¬ã€‚

**sklearnå®ç°**ï¼š`from sklearn.ensemble import AdaBoostRegressor`

**ç‰¹ç‚¹**ï¼š
- âœ… **ç®€å•æœ‰æ•ˆ**ï¼šå†å²æ‚ ä¹…ï¼Œç†è®ºæˆç†Ÿ
- âŒ **å¯¹å™ªå£°æ•æ„Ÿ**ï¼šå¼‚å¸¸å€¼ä¼šè¢«è¿‡åº¦å…³æ³¨
- ğŸ“Š **æ¨èåœºæ™¯**ï¼šæ•°æ®è´¨é‡é«˜çš„å›å½’é—®é¢˜

---

### 2.8 æ¢¯åº¦æå‡å®¶æ—ç»¼åˆå¯¹æ¯”

| æ¨¡å‹ | sklearnå®ç° | æ ¸å¿ƒä¼˜åŠ¿ | è®­ç»ƒæ–¹å¼ | æ­£åˆ™åŒ– | ç‰¹å¾é‡‡æ · | é€‚ç”¨æ•°æ®è§„æ¨¡ | è®¡ç®—æ•ˆç‡ | æ¨èåœºæ™¯ |
|------|-------------|---------|----------|---------|----------|-----------|----------|----------|
| **GradientBoostingRegressor** | `GradientBoostingRegressor` | ç†è®ºæˆç†Ÿï¼Œçµæ´»æŸå¤±å‡½æ•° | ä¸²è¡Œ | æ—  | âŒ | å°-ä¸­æ•°æ®é›† | ä½ | éœ€è¦ç²¾ç»†è°ƒå‚çš„å›å½’ |
| **XGBRegressor** | `XGBRegressor` | ç«èµ›çº§æ€§èƒ½ï¼Œå·¥ç¨‹ä¼˜åŒ–å¥½ | ä¸²è¡Œ | âœ“ | âœ“ | ä¸­-å¤§æ•°æ®é›† | é«˜ | è¿½æ±‚æè‡´æ€§èƒ½çš„å›å½’ |
| **LGBMRegressor** | `LGBMRegressor` | è®­ç»ƒæå¿«ï¼Œå†…å­˜æ•ˆç‡é«˜ | ä¸²è¡Œ | âœ“ | âœ“ | å¤§-è¶…å¤§æ•°æ®é›† | æé«˜ | å¤§æ•°æ®é›†å›å½’é¦–é€‰ |
| **CatBoostRegressor** | `CatBoostRegressor` | å¼€ç®±å³ç”¨ï¼Œå¤„ç†ç±»åˆ«ç‰¹å¾ | ä¸²è¡Œ | âœ“ | âŒ | å°-ä¸­æ•°æ®é›† | ä¸­ | æ··åˆç‰¹å¾çš„å›å½’ |
| **HistGradientBoostingRegressor** | `HistGradientBoostingRegressor` | åŸç”Ÿæ”¯æŒç¼ºå¤±å€¼ï¼Œsklearnè‡ªå¸¦ | ä¸²è¡Œ | âœ“ | âœ“ | ä¸­-å¤§æ•°æ®é›† | é«˜ | å¿«é€ŸåŸå‹å¼€å‘ |
| **AdaBoostRegressor** | `AdaBoostRegressor` | ç®€å•æœ‰æ•ˆï¼Œå†å²æ‚ ä¹… | ä¸²è¡Œ | âŒ | âŒ | å°æ•°æ®é›† | ä½ | æ•°æ®è´¨é‡é«˜çš„å›å½’ |

**å¯¹æ¯”è¦ç‚¹**ï¼š
- **è®­ç»ƒé€Ÿåº¦**ï¼šLGBM > HistGB > XGB > CatBoost > GB > AdaBoost
- **å†…å­˜æ•ˆç‡**ï¼šLGBM > HistGB > XGB > GB â‰ˆ CatBoost > AdaBoost
- **å¤§æ•°æ®é€‚åº”æ€§**ï¼šLGBM > XGB > HistGB > CatBoost > GB > AdaBoost
- **å°æ•°æ®è¡¨ç°**ï¼šAdaBoost > CatBoost > GB > XGB â‰ˆ HistGB > LGBM
- **ç±»åˆ«ç‰¹å¾å¤„ç†**ï¼šCatBoost > XGB â‰ˆ LGBM > HistGB > GB > AdaBoost

---

## 3. æ ‘æ¨¡å‹å®æˆ˜å»ºè®®

### 3.1 å‚æ•°è°ƒä¼˜ç­–ç•¥

**éšæœºæ£®æ—è°ƒå‚é¡ºåº**ï¼š
1. `n_estimators`ï¼šå…ˆè®¾ç½®ä¸€ä¸ªè¶³å¤Ÿå¤§çš„å€¼ï¼ˆå¦‚500ï¼‰
2. `max_depth`ï¼šä»5å¼€å§‹é€æ­¥å¢åŠ 
3. `min_samples_split` å’Œ `min_samples_leaf`ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆ
4. `max_features`ï¼šé»˜è®¤ $\sqrt{p}$ é€šå¸¸å·²ç»å¾ˆå¥½

**æ¢¯åº¦æå‡è°ƒå‚é¡ºåº**ï¼š
1. `n_estimators` å’Œ `learning_rate`ï¼šä¸¤è€…æˆåæ¯”ï¼Œå…ˆå›ºå®šä¸€ä¸ª
2. `max_depth`ï¼šé€šå¸¸3-8ä¹‹é—´
3. æ­£åˆ™åŒ–å‚æ•°ï¼š`reg_alpha`, `reg_lambda`ï¼ˆXGBoost/LightGBMï¼‰
4. é‡‡æ ·å‚æ•°ï¼š`subsample`, `colsample_bytree`

### 3.2 æ€§èƒ½ä¼˜åŒ–æŠ€å·§

**è®­ç»ƒé€Ÿåº¦ä¼˜åŒ–**ï¼š
- ä½¿ç”¨LightGBMæ›¿ä»£XGBoostï¼ˆå¤§æ•°æ®é›†ï¼‰
- å‡å°‘ `n_estimators`ï¼Œå¢åŠ  `learning_rate`
- é™åˆ¶ `max_depth`
- ä½¿ç”¨GPUç‰ˆæœ¬ï¼ˆXGBoost/LightGBMï¼‰

**å†…å­˜ä¼˜åŒ–**ï¼š
- å‡å°‘ `n_estimators`ï¼ˆéšæœºæ£®æ—ï¼‰
- ä½¿ç”¨ `max_bins` å‚æ•°ï¼ˆLightGBMï¼‰
- ç‰¹å¾é€‰æ‹©ï¼Œé™ç»´

**è¿‡æ‹Ÿåˆé˜²æ­¢**ï¼š
- å¢åŠ  `min_samples_leaf`ï¼ˆéšæœºæ£®æ—ï¼‰
- å‡å° `learning_rate`ï¼Œå¢åŠ  `n_estimators`ï¼ˆæ¢¯åº¦æå‡ï¼‰
- ä½¿ç”¨æ­£åˆ™åŒ–å‚æ•°
- Early stoppingï¼ˆæ¢¯åº¦æå‡ï¼‰

---

## æœ¬ç¯‡å°ç»“

**ç¬¬äºŒç¯‡ä»‹ç»äº†å®æˆ˜ä¸­æœ€å¸¸ç”¨çš„æ ‘æ¨¡å‹å’Œæ¢¯åº¦æå‡æ–¹æ³•**ï¼š

âœ… **å†³ç­–æ ‘ä¸éšæœºæ£®æ—**ï¼šä»å•æ£µæ ‘çš„é«˜å¯è§£é‡Šæ€§ï¼Œåˆ°éšæœºæ£®æ—çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ï¼Œå†åˆ°æç«¯éšæœºæ ‘çš„è®­ç»ƒé€Ÿåº¦ä¼˜åŠ¿

âœ… **æ¢¯åº¦æå‡å®¶æ—**ï¼šä»ç»å…¸çš„GradientBoostingï¼Œåˆ°ç«èµ›ç¥å™¨XGBoostï¼Œå†åˆ°å¤§æ•°æ®æ€æ‰‹LightGBMï¼Œä»¥åŠå¼€ç®±å³ç”¨çš„CatBoost

è¿™äº›æ¨¡å‹çš„å…±åŒç‰¹ç‚¹ï¼š
- **å‡†ç¡®æ€§é«˜**ï¼šé€šå¸¸èƒ½è¾¾åˆ°æœ€ä½³æ€§èƒ½
- **ç‰¹å¾å·¥ç¨‹ç®€å•**ï¼šè‡ªåŠ¨å¤„ç†ç‰¹å¾äº¤äº’
- **é²æ£’æ€§å¼º**ï¼šå¯¹å¼‚å¸¸å€¼å’Œå™ªå£°ä¸æ•æ„Ÿ

**å®æˆ˜å»ºè®®**ï¼š
- **å¿«é€ŸåŸå‹**ï¼šRandomForest
- **è¿½æ±‚æè‡´æ€§èƒ½**ï¼šXGBoostæˆ–LightGBM
- **å¤§æ•°æ®é›†**ï¼šLightGBM
- **ç±»åˆ«ç‰¹å¾å¤š**ï¼šCatBoost
- **éœ€è¦è§£é‡Šæ€§**ï¼šDecisionTreeæˆ–RandomForestï¼ˆfeature_importances_ï¼‰

**ä¸‹ä¸€ç¯‡**å°†ä»‹ç»**ç¥ç»ç½‘ç»œã€æ¦‚ç‡æ¨¡å‹ã€æ·±åº¦ç”Ÿæˆæ¨¡å‹ï¼ˆVAEï¼‰**ï¼Œä»¥åŠå®Œæ•´çš„**æ¨¡å‹é€‰æ‹©æŒ‡å—**ï¼Œå¸®åŠ©ä½ åœ¨å®é™…é¡¹ç›®ä¸­åšå‡ºæœ€ä½³é€‰æ‹©ã€‚

---

## å‚è€ƒèµ„æ–™

1. Scikit-learn Documentation: https://scikit-learn.org/
2. XGBoost Documentation: https://xgboost.readthedocs.io/
3. LightGBM Documentation: https://lightgbm.readthedocs.io/
4. CatBoost Documentation: https://catboost.ai/docs/
5. Breiman (2001). "Random Forests"
6. Chen & Guestrin (2016). "XGBoost: A Scalable Tree Boosting System"
7. Ke et al. (2017). "LightGBM: A Highly Efficient Gradient Boosting Decision Tree"
